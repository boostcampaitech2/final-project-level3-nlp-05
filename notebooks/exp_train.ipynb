{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast, BartForConditionalGeneration, PretrainedConfig\n",
    "from transformers import BartTokenizerFast\n",
    "from transformers.models.bart.configuration_bart import BartConfig\n",
    "\n",
    "from model import BartSummaryModelV2\n",
    "from utils import collate_fn, freeze, unfreeze_all, PrintInfo\n",
    "from dataset import SummaryDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load config, tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartSummaryModelV2 were not initialized from the model checkpoint at gogamza/kobart-summarization and are newly initialized: ['classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gogamza/kobart-summarization\"\n",
    "\n",
    "config = BartConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = BartTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "model = BartSummaryModelV2.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/opt/ml/dataset/Training/train.parquet\"\n",
    "train_dataset = SummaryDataset(train_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "    BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: collate_fn(x, pad_token_idx=tokenizer.pad_token_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartSummaryModelV2(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       "  (classification_head): BartClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef189a0d0ad84e5aad4f59e0367741c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/final-project-level3-nlp-05/utils.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs[key].append(torch.tensor(sample[key]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40865/3282539882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# losses.append(ext_out.loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mext_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgen_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 16\n",
    "ext_losses = []\n",
    "gen_losses = []\n",
    "\n",
    "backward_steps = 64\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    i = 0\n",
    "    for idx, batch in tqdm(enumerate(train_dataloader)):\n",
    "        if i % 100 == 0: print(i)\n",
    "        # labels: 생성요약, answers: 추출요약\n",
    "        input_ids = batch[\"input_ids\"].cuda()  # (B, L_src)\n",
    "        attention_mask = batch[\"attention_mask\"].cuda()  # (B, L_src)\n",
    "        answers = batch[\"answers\"].cuda() # 추출요약 (B, 3)\n",
    "        labels = batch[\"labels\"].cuda()   # 생성요약 (B, L_tgt)\n",
    "\n",
    "        ext_out = model.classify(input_ids=input_ids, attention_mask=attention_mask, labels=answers)\n",
    "        \n",
    "        # losses.append(ext_out.loss)\n",
    "        ext_out.loss.backward()\n",
    "\n",
    "        gen_out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # print(ext_out.loss, gen_out.loss)\n",
    "        ext_losses.append(ext_out.loss.item())\n",
    "        gen_losses.append(gen_out.loss.item())\n",
    "\n",
    "        if (i+1) % backward_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        i += 1\n",
    "\n",
    "model.save_pretrained(\"./saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6ff4a75880>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "interval = 100\n",
    "ext_mean = np.array(ext_losses)[:(len(ext_losses)//interval) * interval].reshape(interval, -1).mean(1)\n",
    "gen_mean = np.array(gen_losses)[:(len(ext_losses)//interval) * interval].reshape(interval, -1).mean(1)\n",
    "\n",
    "plt.plot(ext_mean)\n",
    "plt.plot(gen_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  4, 22],\n",
       "        [ 5,  6, 10],\n",
       "        [ 3,  5,  6],\n",
       "        [26, 23, 33]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  3, 22, 18, 19, 21, 16, 30, 33, 28, 29, 31, 34, 32, 27, 26, 20, 23,\n",
       "          9, 17, 11,  8, 12, 13, 25, 15,  5,  1, 14, 10,  0,  7,  6,  2, 24],\n",
       "        [ 5,  6, 10, 27, 28, 32, 31, 30, 33, 34, 25, 26, 23, 24, 17, 22,  4, 21,\n",
       "         19, 29,  3, 20, 13, 14, 18,  1,  8,  7, 16,  0,  9,  2, 15, 12, 11],\n",
       "        [ 3,  5,  6,  9, 24, 19, 31, 33, 25, 23, 21, 20, 26, 28, 27, 32, 34, 29,\n",
       "         30, 22, 18, 13, 17, 16, 14,  7,  2,  0, 15,  4,  1,  8, 12, 11, 10],\n",
       "        [26, 23, 25, 27, 31, 33, 30, 28, 34, 24, 32, 29,  8, 13, 14, 15,  7, 11,\n",
       "         20,  4, 19, 12,  5,  3, 16, 21,  2, 10,  6, 22,  0, 17, 18,  1,  9]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_out.logits.argsort(descending=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
