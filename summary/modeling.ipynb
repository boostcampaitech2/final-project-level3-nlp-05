{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "from model import BartSummaryModelV2, SentenceClassifierOutput\n",
    "from dataset import SummaryDataset\n",
    "from inference import extract_sentences\n",
    "from utils import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartSummaryModelV2 were not initialized from the model checkpoint at gogamza/kobart-summarization and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.dense.bias', 'classification_head.out_proj.bias', 'classification_head.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gogamza/kobart-summarization\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "model = BartSummaryModelV2.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SummaryDataset(\"/opt/ml/dataset/Training/train.parquet\", tokenizer, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, 4, shuffle=False, collate_fn=lambda x: collate_fn(x, tokenizer.pad_token_id, sort_by_length=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 26407,  9770,  ...,     3,     3,     3],\n",
       "         [    0,   255, 11764,  ...,     3,     3,     3],\n",
       "         [    0, 12126,  9506,  ..., 23111, 15964,     1],\n",
       "         [    0, 17493, 17245,  ...,     3,     3,     3]]),\n",
       " 'attention_mask': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       " 'eos_positions': tensor([[ 14,  31,  53,  87, 122, 153, 199, 241, 281, 300, 329, 369, 425,   0,\n",
       "            0,   0,   0,   0],\n",
       "         [ 18,  35,  63,  94, 130, 149, 181, 217, 240, 259, 275, 298, 356,   0,\n",
       "            0,   0,   0,   0],\n",
       "         [ 13,  30,  55,  83, 118, 176, 201, 211, 226, 263, 285, 307, 332, 354,\n",
       "          392, 418, 443, 462],\n",
       "         [ 19,  36,  67,  98, 131, 169, 193, 231, 288, 336,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0]]),\n",
       " 'answers': tensor([[ 2,  3, 10],\n",
       "         [ 2,  4, 11],\n",
       "         [ 3,  5,  7],\n",
       "         [ 2,  3,  4]]),\n",
       " 'labels': tensor([[    0, 12126, 10213,  9506, 14973, 18193, 24873, 24777, 27841, 25486,\n",
       "          14185, 26379, 19609, 10443, 14291, 15912, 14396, 11786, 19609, 15410,\n",
       "          14031, 10386, 12061, 10675, 14303, 20054, 14048, 14355, 14212, 15049,\n",
       "          14291, 14553, 19609, 15231, 16864, 16365, 15828, 26030, 19560, 14063,\n",
       "          11495, 14871, 17074, 12147, 15127, 17489, 15358, 15272, 14432, 14834,\n",
       "          15271, 15243, 15869, 15450, 15364, 14497, 12332, 16516, 12332, 23891,\n",
       "          10586,  9879, 17982, 18290, 15453, 17210,  9754, 17546,     1],\n",
       "         [    0, 11802, 11372, 14953, 21767, 11033, 15447, 19528, 14260, 16084,\n",
       "          16490, 14330, 14143, 11230, 12631, 11863, 16126,  1543, 15081, 10443,\n",
       "          17308, 14330, 20325, 12673, 11207, 10868, 13714, 16503,  9120, 16834,\n",
       "          16503, 12005, 14177, 10339,  9760, 10339, 21401, 19673, 14179, 19126,\n",
       "          14379, 15358,  9120, 21519, 14825, 14590, 22041, 22474, 17976, 13607,\n",
       "          14051,  9123, 24263, 14765, 22897, 14397, 16367,     1,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "         [    0, 12126,  9506, 29632, 12317, 26800, 16435, 14637, 16334, 16667,\n",
       "          14112, 10897, 11211, 27532, 15189, 14055, 22530, 21307, 22560, 20634,\n",
       "          15180, 14210, 14403, 14353, 22920, 27066, 14056, 24002,     1,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "         [    0,  9133, 11747, 14953, 18102, 17403, 19911, 14276, 17203, 16365,\n",
       "          11699, 14477, 14185, 14174, 11471,   373,  8995,   373, 12621,  9754,\n",
       "          10232, 14048, 14331, 13329, 13714, 12061, 10608, 15705, 18102, 12037,\n",
       "          23868, 20964, 20776, 14130,     1,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "              3,     3,     3,     3,     3,     3,     3,     3,     3]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "eos_positions = batch[\"eos_positions\"]\n",
    "answers = batch[\"answers\"]\n",
    "labels = batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inputs = extract_sentences(input_ids, eos_positions, answers, tokenizer)\n",
    "# extraction이 아직 없어서 answers로 대체했습니당\n",
    "# 실제 inference에서는 ext_ids에 들어가는 아이가\n",
    "# 오름차순으로 sorting이 되어 있어야 할 것 같아요! 그래야 순서가 바뀌지 않을 것 같습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([4, 97])\n",
      "attention_mask: torch.Size([4, 97])\n"
     ]
    }
   ],
   "source": [
    "for k, v in gen_inputs.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
